{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poetizer",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D0IfQVzjhyp",
        "colab_type": "code",
        "outputId": "f3f5667a-f6ea-450e-e57d-77bc45e532c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q6JbouWbgCX",
        "colab_type": "code",
        "outputId": "7c2e5b75-daed-4cd6-9191-c6c18f97e3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 28 19:44:29 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8XnekTfmAY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 4,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 50,   # set higher to train the model for longer\n",
        "    'gen_epochs': 10,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': True,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJY19jYkd8va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"dataset.txt\"\n",
        "model_name = 'colaboratory'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YY9MbBYe7z4",
        "colab_type": "code",
        "outputId": "6ed64dea-ea0b-4b3f-a388-75570b4abeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#treino\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=200,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 4-layer, 128-cell LSTMs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0628 14:02:09.435868 139889013430144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training on 1,750,670 character sequences.\n",
            "Epoch 1/50\n",
            "1709/1709 [==============================] - 164s 96ms/step - loss: 3.0956 - val_loss: 2.2338\n",
            "Epoch 2/50\n",
            "1709/1709 [==============================] - 157s 92ms/step - loss: 1.9431 - val_loss: 1.7645\n",
            "Epoch 3/50\n",
            "1709/1709 [==============================] - 157s 92ms/step - loss: 1.6974 - val_loss: 1.6524\n",
            "Epoch 4/50\n",
            "1709/1709 [==============================] - 156s 91ms/step - loss: 1.6111 - val_loss: 1.5969\n",
            "Epoch 5/50\n",
            "1709/1709 [==============================] - 156s 92ms/step - loss: 1.5590 - val_loss: 1.5670\n",
            "Epoch 6/50\n",
            "1709/1709 [==============================] - 157s 92ms/step - loss: 1.5235 - val_loss: 1.5464\n",
            "Epoch 7/50\n",
            "1709/1709 [==============================] - 156s 91ms/step - loss: 1.4966 - val_loss: 1.5329\n",
            "Epoch 8/50\n",
            "1709/1709 [==============================] - 157s 92ms/step - loss: 1.4751 - val_loss: 1.5238\n",
            "Epoch 9/50\n",
            "1709/1709 [==============================] - 157s 92ms/step - loss: 1.4569 - val_loss: 1.5146\n",
            "Epoch 10/50\n",
            "1709/1709 [==============================] - 156s 91ms/step - loss: 1.4410 - val_loss: 1.5097\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            " amor!\n",
            "\n",
            "\n",
            "SONETO DE AMOR\n",
            "\n",
            "A mais estrela de que eu fazia a coisa de mim,\n",
            "E eu sei que se transforma e se desata\n",
            "\n",
            "E a minha mão de ser mais que o meu coração de transformar a minha boca!\n",
            "\n",
            "\n",
            "A CONSELHA \n",
            "\n",
            "Se eu pudesse a esperar a mesma coisa que eu não sei se disse que esta morte é um sonho sem conta de\n",
            "\n",
            "nha boca intensidade\n",
            "\n",
            "E a minha alma a mim me deixa a mesma coisa que eu sou mesmo.\n",
            "\n",
            "\n",
            "SONETO DE JANTE\n",
            "\n",
            "\n",
            "O que se desasa e não sei que se deseja e se conta.\n",
            "\n",
            "\n",
            "A MODA \n",
            "\n",
            "Sou um pouco e a minha mão de mim,\n",
            "E a minha alma de teu ser de mim,\n",
            "\n",
            "E eu sei que se não sou tão belo que se deseja a minha beleza,\n",
            "\n",
            "\n",
            "s,\n",
            "que nao sei que se desabaram a minha mão de ser mais fundo.\n",
            "\n",
            "A mulher que não sei que se tem que ser mais que eu sou menos tem a mesma coisa que não se aproxima e se esquece.\n",
            "\n",
            "A mulher que não tem comer no que se desaparece\n",
            "De tudo que é mais que a minha mãe se abre um pouco,\n",
            "e a mesa de mim não \n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            " morte\n",
            "ao que se alimenta a serra de alto\n",
            "\n",
            "Sem poder de nosso dia.\n",
            "\n",
            "\n",
            "Depois de ti, minha frente espantada.\n",
            "\n",
            "A mesa de um sonho com um rosto muito por ti penso e diga que não sabe de nós se acontecem a mim com a minha infância\n",
            "Que chora a noite e o cheiro de teu coração.\n",
            "\n",
            "Se és contra a mim bem levan\n",
            "\n",
            "pelo meu corpo e com a própria bana em que eu sinto\n",
            "Não seria as mãos da mala com as coisas!\n",
            "\n",
            "\n",
            "SENESTAS\n",
            "\n",
            "Este que se esforço, e sorria, e depois de flores\n",
            "que bem sei com a minha mãe para nós,\n",
            "E a minha carta e as mais comovidas\n",
            "E o teu corpo e a vida é o mundo.\n",
            "\n",
            "A mala é um castelo entre as mãos e \n",
            "\n",
            "nte,\n",
            "inteligência de minha alma,\n",
            "e vagamente foi com a morte e pensa procurada.\n",
            "\n",
            "Se eu faço acrescente, que mais serei com a minha mãe está mais aflita\n",
            "\n",
            "\n",
            "não sabe de me transformar-me,\n",
            "Onde a mão de ti e de ser veneno.\n",
            "Quem me dera meu amor que não passa de mim.\n",
            "\n",
            "\n",
            "Intensa ri\n",
            "\n",
            "A semana de mim mesmo a\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ento.\n",
            "Contude ao fundo dujo-frafundo mercador!\n",
            "\n",
            "Radiante-me que pertença da losa!...\n",
            "O dia dessensistir a sorte de parede.\n",
            "\n",
            "Se pudesse sim, a meiga, e também eu por que?\n",
            "Impera a vida, que qual pode tempo\n",
            "o orbe e garonal\n",
            "o homem e se esvazia\n",
            "\n",
            "\n",
            "vida\n",
            "\n",
            "\n",
            "Quem quoria normar\n",
            "que sabe como paixão.\n",
            "De nega\n",
            "\n",
            "u\n",
            "Qe frio em beca e cinzal comigo é o homem, amigaria\n",
            "Impensável com a insâname em alucinacao do ritmo acesado...\n",
            "Amarra prostra para depois como elas).\n",
            "É uma álgebra p--...\n",
            "Estre casas grandes estes livros e das\n",
            "escapadalhas,\n",
            "quem parece,\n",
            "que em vão com voz dourada,\n",
            "vagada\n",
            "entre rosaco, pelaespasso\n",
            "\n",
            "de,\n",
            "o meio morrer,\n",
            "sempre pardadas, mojadas de seres e vaguei,\n",
            "ainda põe tão hoje quere.\n",
            "\n",
            "Rara a eles, perfuras de íngulos emotivos\n",
            "já ter seus cantaracos\n",
            "se com ele cuida!\n",
            "\n",
            "Poeta embora outra, ou sentado em que nenhum deus!\n",
            "E as vezes seio todo a todos nos é,\n",
            "tomar uma rua apidando substancia,\n",
            "O se\n",
            "\n",
            "Epoch 11/50\n",
            " 136/1709 [=>............................] - ETA: 1:44 - loss: 1.4048"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhkKs5c-iVMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HAqR5OwigZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baixando os pesos, vocab e config\n",
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUCpsn8Gij6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usar esse trecho de codigo para carregar modelos no pc\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "\n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}